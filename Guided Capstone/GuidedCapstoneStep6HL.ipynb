{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf5CmXQCZyF1"
   },
   "source": [
    "# Guided Capstone Step 6. Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbZXsVevfr9M"
   },
   "source": [
    "**The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    "3.   Exploratory Data Analysis \n",
    " \n",
    "4.   Pre-processing and Training Data Development\n",
    "\n",
    "5.  Modeling\n",
    "\n",
    "6.   **Documentation**\n",
    "  * Review the Results\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation\n",
    "  * Create a Project Report \n",
    "  * Create a Slide Deck for the Executive Audience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-oGciwnGUYk"
   },
   "source": [
    "In this guided capstone we are going to revisit many of the actions we took in the previous guided capstone steps. This gives you the opportunity to practice the code you wrote to solve the questions in step 4 and 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8xfkAqqZyF2"
   },
   "source": [
    "**<font color='teal'> Start by loading the necessary packages and printing out our current working directory just to confirm we are in the correct project directory. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry6WPL5eZyF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\\SpringBoard\\Guided Capstone\n",
      "step3_output.csv is in working dir\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>state</th>\n",
       "      <th>summit_elev</th>\n",
       "      <th>vertical_drop</th>\n",
       "      <th>trams</th>\n",
       "      <th>fastEight</th>\n",
       "      <th>fastSixes</th>\n",
       "      <th>fastQuads</th>\n",
       "      <th>quad</th>\n",
       "      <th>triple</th>\n",
       "      <th>...</th>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <th>Snow Making_ac</th>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <th>yearsOpen</th>\n",
       "      <th>averageSnowfall</th>\n",
       "      <th>AdultWeekday</th>\n",
       "      <th>AdultWeekend</th>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hilltop Ski Area</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2090</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>152.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sunrise Park Resort</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>11100</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>800.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Yosemite Ski &amp; Snowboard Area</td>\n",
       "      <td>California</td>\n",
       "      <td>7800</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>174.873239</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Donner Ski Ranch</td>\n",
       "      <td>California</td>\n",
       "      <td>8012</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>505.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>82.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.00000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>June Mountain</td>\n",
       "      <td>California</td>\n",
       "      <td>10090</td>\n",
       "      <td>2590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>174.873239</td>\n",
       "      <td>152.111111</td>\n",
       "      <td>58.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>57.916957</td>\n",
       "      <td>64.16681</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name       state  summit_elev  vertical_drop  \\\n",
       "0               Hilltop Ski Area      Alaska         2090            294   \n",
       "1            Sunrise Park Resort     Arizona        11100           1800   \n",
       "2  Yosemite Ski & Snowboard Area  California         7800            600   \n",
       "3               Donner Ski Ranch  California         8012            750   \n",
       "4                  June Mountain  California        10090           2590   \n",
       "\n",
       "   trams  fastEight  fastSixes  fastQuads  quad  triple  ...  \\\n",
       "0      0        0.0          0          0     0       1  ...   \n",
       "1      0        0.0          0          1     2       3  ...   \n",
       "2      0        0.0          0          0     0       1  ...   \n",
       "3      0        0.0          0          0     0       1  ...   \n",
       "4      0        0.0          0          2     0       0  ...   \n",
       "\n",
       "   SkiableTerrain_ac  Snow Making_ac  daysOpenLastYear  yearsOpen  \\\n",
       "0               30.0       30.000000        150.000000       36.0   \n",
       "1              800.0       80.000000        115.000000       49.0   \n",
       "2               88.0      174.873239        110.000000       84.0   \n",
       "3              505.0       60.000000        163.000000       82.0   \n",
       "4             1500.0      174.873239        152.111111       58.0   \n",
       "\n",
       "   averageSnowfall  AdultWeekday  AdultWeekend  projectedDaysOpen  \\\n",
       "0             69.0     30.000000      34.00000              152.0   \n",
       "1            250.0     74.000000      78.00000              104.0   \n",
       "2            300.0     47.000000      47.00000              107.0   \n",
       "3            400.0     75.000000      75.00000              170.0   \n",
       "4            250.0     57.916957      64.16681              128.0   \n",
       "\n",
       "   NightSkiing_ac  clusters  \n",
       "0            30.0         0  \n",
       "1            80.0         1  \n",
       "2             0.0         1  \n",
       "3             0.0         1  \n",
       "4             0.0         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "current_dir = os.getcwd()\n",
    "# This notebook is in public repro.\n",
    "short_current_dir = current_dir[current_dir.find('SpringBoard'):] \n",
    "print('...\\\\'+short_current_dir)\n",
    "file  = 'step3_output.csv'\n",
    "if file in os.listdir('.\\\\data\\\\'):\n",
    "    path=current_dir\n",
    "    print(file+f' is in working dir')\n",
    "else:\n",
    "    print(file+f' is not in working dir. Change directory!')\n",
    "df0 = pd.read_csv(f'{path}\\\\data\\\\step3_output.csv')\n",
    "df0.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0HTP9cF2GUYs"
   },
   "source": [
    "## Fit Models with Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2FmSbtCGUYt"
   },
   "source": [
    "**<font color='teal'> Using sklearn fit the model you chose in Guided Capstone 5 on your training dataset. This includes: creating dummy features for states if you need them, scaling the data,and creating train and test splits before fitting the chosen model.Also, remember to generate a model performance score(MAE, or explained variance) based on the testing hold-out data set.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReRSy1yFGUYu"
   },
   "source": [
    "#### Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRhPGbqPGUYv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE = 5.813252474993876\n",
      " explained variance score = 0.8265339490011624\n",
      " mean absolute error = 4.726327139935685  \n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df0, columns=['state'])\n",
    "# first we import the preprocessing package from the sklearn library\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "# Declare an explanatory variable, called X,and assign it the result of dropping 'Name' and 'AdultWeekend' from the df\n",
    "X = df.drop(['Name', 'summit_elev', 'AdultWeekend'], axis=1)\n",
    "\n",
    "# Declare a response variable, called y, and assign it the AdultWeekend column of the df \n",
    "y = df.AdultWeekend\n",
    "\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = pp.StandardScaler().fit(X)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled=scaler.transform(X) \n",
    "\n",
    "# Import the train_test_split function from the sklearn.model_selection utility.  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y = y.ravel()\n",
    "\n",
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=1)\n",
    "\n",
    "#all first model set\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)\n",
    "\n",
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "# You might want to use the explained_variance_score() and mean_absolute_error() metrics.\n",
    "# To do so, you will need to import them from sklearn.metrics. \n",
    "# You can plug y_test and y_pred into the functions to evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "sqrt = np.sqrt\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "exvarscore = explained_variance_score(y_test, y_pred)\n",
    "mean_abs_err= mean_absolute_error(y_test, y_pred)\n",
    "print(f' RMSE = {rmse}\\n explained variance score = {exvarscore}\\n mean absolute error = {mean_abs_err}  ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGizyeLZGUYz"
   },
   "source": [
    "## Review the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Lhu-qisGUY0"
   },
   "source": [
    "**<font color='teal'> Now, let's predict the Big Mountain Weekend price with our model in order to provide a recommendation to our managers on how to price the `AdultWeekend` lift ticket. First we need to find the row for Big Mountain resort in our data using string contains or string matching.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXnx_IuEGUY1"
   },
   "outputs": [],
   "source": [
    "#df[df['Name'].str.contains('Big Mountain')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83-jO9hPGUY4"
   },
   "source": [
    "**<font color='teal'> Prepare the Big Mountain resort data row as you did in the model fitting stage.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWH_q9YOGUY5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2BCFqZYBGUY9"
   },
   "source": [
    "**<font color='teal'> Predict the Big Mountain resort `Adult Weekend` price and print it out.</font>** This is our expected price to present to management. Based on our model given the characteristics of the resort in comparison to other ski resorts and their unique characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XebWxxTMGUY-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5BvguMLGUZB"
   },
   "source": [
    "**<font color='teal'> Print the Big Mountain resort actual `Adult Weekend` price.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WyxTHtL2GUZC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0Yli8MXGUZH"
   },
   "source": [
    "**<font color='teal'> As part of reviewing the results it is an important step to generate figures to visualize the data story. We can use the clusters we added to our data frame to create scatter plots for visualizing the Adult Weekend values compared to other characteristics. Run the example below to get you started and build two or three more figures to include in your data story telling.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWtr873fGUZI"
   },
   "outputs": [],
   "source": [
    "#plt.scatter(df['summit_elev'], df['vertical_drop'], c=df['clusters'], s=50, cmap='viridis', label ='clusters')\n",
    "#plt.scatter(ac['summit_elev'], ac['vertical_drop'], c='black', s=100)\n",
    "#plt.xlabel('summit_elev')\n",
    "#plt.ylabel('vertical_drop')\n",
    "#plt.title('summit_elev by vertical_drop by cluster')\n",
    "#plt.savefig('figures/fig1.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "530JtuJxGUZL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGvf4kTwGUZR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYZB84hYGUZU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "giLKE2WMGUZh"
   },
   "source": [
    "## Finalize Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pps_ASHoGUZi"
   },
   "source": [
    " Making sure our code is well organized and easy to follow is an important step. This is the time where you need to review the notebooks and Python scripts you've created and clean them up so they are easy to follow and succinct in nature. Addtionally, we will also save our final model as a callable object using Pickle for future use in a data pipeline. Pickle is a module that serializes (and de-serializes) Python objects so that they can become executable objects like functions. It's used extensively in production environments where machine learning models are deployed on an industrial scale!**<font color='teal'> Run the example code below to save out your callable model. Notice that we save it in the models folder we created in our previous guided capstone step.</font>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_h0tkt_GUZj"
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#s = pickle.dumps(model)\n",
    "#from joblib import dump, load\n",
    "#dump(model, 'models/regression_model_adultweekend.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTVrVlerGUZn"
   },
   "source": [
    "## Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thEMyu-DGUZo"
   },
   "source": [
    "For model documentation, we want to save the model performance metrics as well as the features included in the final model. You could also save the model perfomance metrics and coefficients fo the other models you tried in case you want to refer to them later. **<font color='teal'> Create a dataframe containing the coefficients and the model performance metrics and save it out as a csv file, then upload it to your github repository.</font>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "278tnHLlGUZp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CEOoBLFGUZr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RtEspslPZyGY",
    "s0DokMkAZyGc",
    "2iuitnKcZyHS",
    "iAWQxougZyHW",
    "ThMTimlBZyHZ",
    "QwZ-LkjXZyHt",
    "srtXEA3N4-Y9",
    "ChVreJupZyIA",
    "zDgSSsq1ZyID",
    "I3GYKWfi5Llg",
    "pmMvrhbI-viE",
    "ZXDPkW3UZyIX",
    "Dnc_vHQLZyId",
    "daJxuJ-dZyIg",
    "mAQ-oHiPZyIn",
    "hnGOsp3mZyIp"
   ],
   "name": "GuidedCapstoneStep6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
